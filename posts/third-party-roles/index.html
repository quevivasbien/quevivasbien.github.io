<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="../../favicon.png" />
		<meta name="viewport" content="width=device-width" />
		<title>Que vivas bien</title>
    
		<!-- Google Fonts -->
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
		<!-- Font Awesome -->
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" />
		<!-- Katex stylesheet -->
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
		<style>
		</style>

		
		<link href="../../_app/immutable/assets/0.d34f62d4.css" rel="stylesheet">
		<link rel="modulepreload" href="../../_app/immutable/entry/start.897e7133.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/index.f5836231.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/singletons.5e031965.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/paths.4f49a2e1.js">
		<link rel="modulepreload" href="../../_app/immutable/entry/app.6ab0b84f.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/preload-helper.a4192956.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/0.f94e2f9b.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/2.5679a1a0.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/TextContent.517b7305.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/32.34186d7f.js">
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">



<div class="max-w-xl mx-auto sticky top-0 z-10"><nav class="bg-red-400 sm:rounded-b-md shadow-md"><div class="mx-auto px-2 sm:px-6 lg:px-8"><div class="relative flex h-16 items-center justify-between"><div class="flex flex-1 items-center sm:items-stretch justify-start"><div class="flex flex-shrink-0 items-center">
                <a href="/" class="text-white font-bold text-2xl hover:text-white">Que vivas bien</a></div></div>
            
            <div class="absolute inset-y-0 right-0 flex items-center sm:hidden">
                <button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-gray-400 hover:bg-gray-700 hover:text-white focus:outline-none focus:ring-2 focus:ring-inset focus:ring-white" aria-controls="mobile-menu" aria-expanded="false"><span class="sr-only">Open main menu</span>
                  
                  <svg class="block h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg>
                  
                  <svg class="hidden h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12"></path></svg></button></div>
            
            <div class="absolute inset-y-0 right-0 hidden sm:flex items-center pr-2 sm:static sm:inset-auto sm:ml-6 sm:pr-0"><a href="/" class="text-white hover:bg-rose-100 hover:text-gray-600 px-2 py-2 rounded-md text-sm font-medium">Home</a>
                <a href="/about/" class="text-white hover:bg-rose-100 hover:text-gray-600 px-2 py-2 rounded-md text-sm font-medium">About</a>
                <a href="/archive/" class="text-white hover:bg-rose-100 hover:text-gray-600 px-2 py-2 rounded-md text-sm font-medium">Archive</a></div></div></div>
      
        
        </nav></div>

<div class="max-w-3xl mx-auto my-2 bg-white rounded-md shadow-md py-4 px-4 sm:px-8 space-y-3">

<h1>Roles for third parties in promoting safe AI innovation</h1>
<p><em>This is a summary of a paper I have been working on with Robert Trager and Nicholas Emery-Xu. Feel free to reach out for the full version.</em></p>
<p>This paper builds on <a href="https://arxiv.org/pdf/2302.11436.pdf" rel="nofollow">our previous work</a>, where
we introduced a model where innovators compete to be the first to
develop advanced AI technology, allocating resources between safety and
performance research. In that paper, we made some observations on how
changes in compute pricing affect safety. Here, we suggest and evaluate
a few other ways that third parties could promote safer strategies on
the part of AI innovators.</p>
<p>The basic interventions we look at are:</p>
<ol><li>Providing subsidies that can be used only for safety research</li>
<li>Providing subsidies only if innovators can certify they will meet a threshold level of safety</li>
<li>Penalizing innovators if they fail to meet a threshold level of safety</li></ol>
<p>Roughly speaking, all of these interventions are better at promoting
safety than simply providing compute subsidies to be used at innovators’
discretion. The main takeaway is that interventions 2 and 3 can be significantly more effective (both in terms of cost and the resulting increase in safety) than intervention 1.</p>

<h2>Targeted subsidies for safety spending</h2>
<p>Here, we consider the case where innovators receive discounted prices
for inputs to their safety research programs (and not to any programs
meant to improve performance/capabilities).</p>
<p>Key takeaways:</p>
<ul><li>If all innovators are roughly identical, subsidizing everyone’s safety spending always increases equilibrium safety.</li>
<li>If innovators are not identical, or we offer different subsidies to different innovators, this intervention may not be as effective, or may be counterproductive, but it at least seems difficult to actively do harm.</li></ul>
<h2>Subsidies contingent on safety certification</h2>
<p>Here, we consider the case where a third party audits innovators’
spending plans; if their plans fulfill some threshold safety
requirement, they are certified safe and receive a subsidy on all their
spending.</p>
<p>Key takeaways:</p>
<ul><li>If the threshold safety requirement is too low or too high, this policy is ineffective (innovators will either qualify for the subsidy without changing their behavior or not bother qualifying since the requirements are too difficult to fulfill).</li>
<li>If the threshold safety requirement is chosen appropriately (as high as possible while still being attractive to fulfill), this can be a very effective intervention.</li></ul>
<h3 id="an-important-clarification">An important clarification</h3>
This intervention is not the same as identifying actors who are
deemed to be <q>safer</q> than others and offering them subsidies: the
key difference is that here the subsidy is based on the level of safety
that will be achieved <em>after the fact</em>. That is, innovators only
qualify if they will achieve a safety target after being given the
subsidy. This avoids the potential problem of actors who are relatively
safe before being subsidized becoming less safe after being subsidized,
or less safety-conscious actors not selected for subsidies behaving
recklessly in reaction to their safety-conscious competitors recieving
subsidies.
<h2>Penalties for safety violations</h2>
<p>Here, we again consider a case where a third party audits innovators
and certifies them as safe (or not). However, in this case, there is no
subsidy for passing the audit; instead, innovators who fail are
penalized.</p>
<p>Key takeaways:</p>
<ul><li>This exhibits similar characteristics to the previous intervention (where certified innovators receive subsidies rather than escaping penalties).</li>
<li>Ideally, in equilibrium, nobody pays the penalties, and all innovators act safely at no cost to third parties.</li></ul>
<h3>Why would innovators agree to this?</h3>
<p>An AI race may behave like a prisoner’s dilemma, where everyone would
prefer to adopt safer strategies but won’t since defecting (taking a
riskier, high-performance, strategy) while everyone else is playing safe
destabilizes the equilibrium. Making defection more costly may therefore
be desirable to everyone if it makes the case where everyone plays
safely a stable equilibrium. (Innovators may actually prefer more severe
penalties if that is what it takes to ensure that their competitors
won’t defect.)</p></div>
<div class="max-w-xs mx-auto py-4"><footer class="bg-red-400 rounded-lg shadow-md">
        <div class="flex flex-row justify-center"><a class="flex mx-4 my-2 text-2xl text-white" href="https://github.com/quevivasbien/"><i class="fab fa-github"></i></a>
                <a class="flex mx-4 my-2 text-2xl text-white" href="mailto:jensenm@uchicago.edu"><i class="fa fa-envelope"></i></a>
                <a class="flex mx-4 my-2 text-2xl text-white" href="https://www.linkedin.com/in/mckaydjensen/"><i class="fab fa-linkedin"></i></a></div></footer></div>
<div class="flex flex-col items-center justify-center pb-3"><div>goodness, truth, and <span>humankind</span></div></div>


			
			<script>
				{
					__sveltekit_11yb9nj = {
						base: new URL("../..", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null,null];

					Promise.all([
						import("../../_app/immutable/entry/start.897e7133.js"),
						import("../../_app/immutable/entry/app.6ab0b84f.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2, 32],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
