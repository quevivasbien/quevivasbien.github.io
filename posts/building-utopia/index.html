<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="../../favicon.png" />
		<meta name="viewport" content="width=device-width" />
		<title>Que vivas bien</title>
    
		<!-- Google Fonts -->
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
		<!-- Font Awesome -->
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" />
		<!-- Katex stylesheet -->
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
		<style>
		</style>

		
		<link href="../../_app/immutable/assets/0.81f0aa6c.css" rel="stylesheet">
		<link rel="modulepreload" href="../../_app/immutable/entry/start.e7abbd9d.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/index.cb9bf0be.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/singletons.47516ef9.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/paths.5912b99c.js">
		<link rel="modulepreload" href="../../_app/immutable/entry/app.6de9baa2.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/preload-helper.41c905a7.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/0.a957b413.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/2.a4cedfda.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/TextContent.1c34d419.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/13.734846a5.js">
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">


<div class="max-w-xl mx-auto sticky top-0 z-10"><nav class="bg-red-400 sm:rounded-b-md shadow-md"><div class="mx-auto px-2 sm:px-6 lg:px-8"><div class="relative flex h-16 items-center justify-between"><div class="flex flex-1 items-center sm:items-stretch justify-start"><div class="flex flex-shrink-0 items-center">
                <a href="/" class="text-white font-bold text-2xl hover:text-white">Que vivas bien</a></div></div>
            
            <div class="absolute inset-y-0 right-0 flex items-center sm:hidden">
                <button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-gray-400 hover:bg-gray-700 hover:text-white focus:outline-none focus:ring-2 focus:ring-inset focus:ring-white" aria-controls="mobile-menu" aria-expanded="false"><span class="sr-only">Open main menu</span>
                  
                  <svg class="block h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg>
                  
                  <svg class="hidden h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12"></path></svg></button></div>
            
            <div class="absolute inset-y-0 right-0 hidden sm:flex items-center pr-2 sm:static sm:inset-auto sm:ml-6 sm:pr-0"><a href="/" class="text-white hover:bg-rose-100 hover:text-gray-600 px-2 py-2 rounded-md text-sm font-medium">Home</a>
                <a href="/about/" class="text-white hover:bg-rose-100 hover:text-gray-600 px-2 py-2 rounded-md text-sm font-medium">About</a>
                <a href="/archive/" class="text-white hover:bg-rose-100 hover:text-gray-600 px-2 py-2 rounded-md text-sm font-medium">Archive</a></div></div></div>
      
        
        </nav></div>

<div class="max-w-3xl mx-auto px-2 sm:px-6 lg:px-8 pt-2"><div class="bg-white rounded-md shadow-md p-4 space-y-3">

<h1>Building utopia</h1>

<h2>What is my goal? What is humanity’s goal?</h2>

<p>I’ve been spending a lot of time reading and thinking about extending ethics
    — specifically, the possible answers to the question, “What should I do?” —
    from a personal level to the level of groups of individuals, up to the level
    of the entirety of humankind and beyond. My thinking on this subject is
    largely based on <a href="/posts/deeper-with-axiom-m/">my idea of desire satisfaction as a reasonable basis for moral thinking</a>, as well as the sort of thinking that underlies the traditional economic
    analysis of well-being, which is strongly rooted in utilitarianism. My
    interest in this stems both from a personal fascination, almost an
    obsession, with thinking carefully about what I <em>should</em> spend my
    time and resources doing (How is it that everyone is not constantly asking
    this question?), and from my professional stake in understanding how people
    go about translating their preferences into action and how these individual
    preferences and actions interact on a larger scale to produce the
    sophisticated social mechanics of communities, nations, and international
    bodies: I am about to be submerged full time in rigorous study whose
    theoretical underpinnings rely on specific, technical assumptions about how
    all this works, so it only makes sense to carefully consider how appropriate
    those assumptions are and how we can reasonably translate the positive
    declarations of empirical economic analysis (and scientific investigation
    more generally) into normative statements about <em>what </em>we should
    collectively be using our finite resources for. Specifically, I want to
    carefully consider what the priorities of human society should be and how I
    can use my own resources and aptitudes to contribute to those priorities.
</p>



<h3>Aggregating preferences</h3>

<p><em>(Note: unless you like mathematizing everything like I do, you might
        want to just skim this section and get on to the content below.)</em></p>

<p>As I have written before, a good starting point for this sort of thinking is
    to ask, “What is it that I want?” and then orient one’s actions in such as a
    way as to achieve the state of being that best satisfies those wants. This
    is very similar to the general approach used in microeconomic theory, where
    individuals are assumed to have a set of <a href="https://quevivasbien.wordpress.com/2019/07/12/formalizing-the-idea-of-preference/">well-behaved preferences</a> that can be assumed to be modeled by a “utility function” that assigns a state
    of well-being to every possible collection of resources and circumstances a person
    may have. A basket of goods is associated with a higher value of a given person’s
    utility function if and only if that person’s well-being is higher with that
    basket of goods. This mathematical formalization of preferences is used to quantitatively
    describe the ways in which people interact and form markets to exchange goods
    so as to maximize their individual utilities.
</p>

<p>It is one thing to analyze the ways, in line with my proposed framework,
    that people go about satisfying their desires, or the ways, according to the
    standard microeconomic model, that the simultaneous efforts of individuals
    to maximize their utilities give rise to a system of prices and exchange of
    goods, but it is quite another thing to take these ideas and use them to say
    something about how the states of well-being of the people comprising a
    social group are related to the collective well-being of the society that
    they constitute. One idea I have proposed as a way of thinking about this is
    to take the natural extension of the desire satisfaction model and assert
    that <a href="/posts/very-rough-moral-theory/">social groups should act in such a way as to achieve the “desires”
        expressed by the group “consciousness”</a>
    (i.e. the ideas expressed via conversation within the group) — that is, to assume
    that the collective well-being of a social group is increased by pursuing actions
    that place the group more in line with the desires expressed by the combined
    voices of the group, with the converse also being true. The difficulty is, of
    course, figuring out how exactly the disparate expressed opinions of a group
    combine to form a collective voice, but this is of course also a difficulty on
    the personal level — how do the various voices within one’s own head combine
    to give an experience of conscious identity? This same difficulty has been noted
    by economic theorists in their preference- and utility-based model. On the individual
    level, the standard economic model does not allow for a person holding contradictory
    or otherwise inconsistent preferences, simultaneous sets of distinct preferences,
    or preferences that change significantly over time (although
    <a href="/posts/deeper-with-axiom-m/">I have tried to address some of those problems</a>
    in my own thinking). On the collective level, economic thinkers have gone so
    far as to prove that, under certain assumptions,
    <a href="https://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem">it is mathematically
        <em>impossible</em> to construct a system for transforming individual preferences
        into a consistent set of preferences for the group as a whole</a>
    (roughly, there is no perfect ranked-choice voting system). The situation is
    a bit less bleak if the assumptions involved are relaxed a bit (and the
    literature surrounding this problem is
    <a href="https://en.wikipedia.org/wiki/Social_choice_theory">really quite interesting</a>), but the fact remains that the way in which individual preferences/states
    of well-being should be agglomerated is far from obvious. Even so, I think
    it is still in many cases reasonable to make some basic assertions about
    what social groups want and what they should do to move toward those wants.
    <strong>The rest of this essay is an exploration of what it is possible to say
        about the collective desires of all of humanity and what I think we
        ought to do to maximize our chances of fulfilling those desires.</strong></p>

<h3>What humanity wants</h3>

<p>As detailed above, it is hard to say in a rigorous and exact fashion what
    human society wants on most issues, but I can propose some basic wants based
    on desires that are commonly held by most people and/or frequently show up
    in public discourse:
</p>

<ul><li>Humanity wants to survive.</li>
    <li>Humanity wants to provide pleasurable and meaningful lives to its
        constituent persons.
    </li>
    <li>Humanity wants to increase in knowledge and understanding about how the
        physical world works and apply that knowledge to technological
        development.
    </li>
    <li>Humanity wants to be wealthier (in the sense of having the capability to
        produce more goods and services; here I refer to wealth as essentially
        identical to power — money is strictly speaking only a conceptual
        representation of power and may in fact be mostly unnecessary in a
        sufficiently advanced society).
    </li>
    <li>Humanity wants to produce monuments to its culture (literal monuments,
        works of art, bodies of literature, music, etc.).
    </li>
    <li>Humanity wants to provide certain rights to, and enforce some sort of
        social justice among, its constituent persons. (This one is a somewhat
        more recent desire, manifest with the rise of <a href="https://en.wikipedia.org/wiki/Liberalism">liberal political thinking</a> since the Enlightenment a few centuries back. This way of thinking is of
        course not universal, but does hold great sway in many parts of the modern
        world.)
    </li>
    <li>Humanity wants to be in line with a higher power. (Although this
        particular desire takes different forms compared to times past, it is
        still a significant motive in most people and thus in humankind
        collectively.)
    </li></ul>

<p>This list is not intended to be exhaustive, but I think it provides a
    reasonable foundation to explain most of the human dynamics we see in global
    events and to provide a starting point for answering the question, “What
    should we do?”
</p>

<h2>What is our potential?</h2>

<p>I want to paint a mental image of what <em>could</em> be possible, what human
    society might roughly look like if we managed to robustly satisfy the collective
    desires I’ve listed above. This is by no means a novel exercise: people have
    been imagining up utopias probably since stories have been told. However, I think
    this is a worthwhile train of thought, as it can help us determine what we should
    be working toward and start to consider what we ought to be doing right now to
    get ourselves there.
</p>

<p>First, to satisfy the desire to survive, we need to still be around. This
    seems quite obvious but may be easier said than done. I’ll consider some
    specific ways that things could go wrong here in the next section.
</p>

<p>Given that humankind is still extant in our hypothetical future, the things
    necessary to satisfy the other collective desires I’ve proposed are for the
    most part intertwined and complementary, although some are a bit at odds
    with each other. If we manage to continue improving production-related
    technology to the point where we can efficiently and sustainably make use of
    raw materials and available labor, it is possible that humanity may, in the
    future, <a href="https://en.wikipedia.org/wiki/Post-scarcity_economy">exist in a post-scarcity economy</a>. Individuals living in such a situation would be principally concerned not
    with making a living, but with pursuing goals, activities, and relationships
    that give them pleasure, and — importantly — provide them with a sense of
    meaning. It is likely that most essential production would be automated,
    with robotic systems proving much more effective and cost-efficient than
    humans at performing most (if not all) tasks; although people would likely
    still pursue some sort of work as a type of meaning-making, such work would
    not be strictly necessary.
</p>

<p>I am of the persuasion that automation technology can potentially progress
    to the point where computers can cognitively exceed humans substantially in
    every respect — any argument to the contrary seems to hinge on the
    assumption that there is something special about the human mind that can not
    be replicated mechanistically, but I see no reason why this would be the
    case: the brain is a fantastically complicated physical system but still a
    physical system — because of this, machines may not only be the means of
    production for society but also the principal scientists, engineers, and
    decision makers. This does not mean that the course of society would run
    contrary to the interests of human kind, since, with sufficient care, it is
    reasonable to believe that the thinking machines could be in the first place
    designed to act in the interest of the human race, hopefully even better
    than if humans were still directly in charge. People would likely also still
    be heavily involved in scholarly, constructive, and creative tasks — just
    because someone or something else can do something better than you doesn’t
    mean that you doing that thing isn’t still worthwhile or at the very least
    entertaining. Humans would, every day, produce incredible creative works far
    exceeding anything we see today.
</p>

<p>Medical technology would have reached the point where disease had been
    essentially eradicated, and humans could prolong their lives as long as
    desired. We would be experts at maintaining excellent mental health,
    ensuring that people would not be detoured from well-being by unwanted and
    unavoidable maladies of the mind. Some of these advances would, perhaps, be
    facilitated by genetic engineering of human biology itself, although before
    tampering with our own makeup we would certainly want to consider carefully
    whether the changes we made were in fact in line with our long-term desires.
</p>

<p>With practically unlimited resources, overpopulation would not be too much
    of a concern, so the human race could potentially keep growing. Individuals
    and couples could choose to have and raise children, although their skill at
    child-rearing and the resources available to support them in doing so would
    be much greater than is typical today. Again, because the principal task of
    people would be meaning-making, and close relationships are an important
    source of meaning, romantic, platonic, and family relationships would still
    play a key part in people’s lives.
</p>

<p>Various human rights would be guaranteed to all people (probably something
    like the <a href="https://www.un.org/en/universal-declaration-human-rights/">UN’s Universal Declaration of Human Rights</a>, but adapted to the specific concerns of the time). In general,
    institutions would be set up to provide equality of opportunity in a
    <a href="https://en.wikipedia.org/wiki/John_Rawls">Rawlsian</a> sense. It is
    likely that many people would still follow religious traditions, although the
    beliefs associated with those religions would evolve over time to be compatible
    with a highly knowledgeable, liberal, and technologically advanced society.
</p>

<h2>What could go wrong?</h2>

<p>Talking about possible utopian states does little good without a plan to get
    there and an understanding of the possible road blocks along the way. After
    all, the numerous attempts made to establish the perfect society have to
    this point dissolved or, often, ended in disaster — Sir Thomas More was
    unintentionally prescient in coining the name “<a href="https://en.wikipedia.org/wiki/Utopia_(book)">Utopia</a>” after the Greek for “no place.” I can identity a few ways in which we may
    be derailed before reaching the sort of state I described in the previous
    section. We should take these threats seriously and make efforts now to
    avoid them.
</p>

<h3>Extinction</h3>

<p>Humanity faces several existential threats that could lead to its extinction
    or at least to its irreversible dwindling. Some thinkers have suggested that <a href="https://web.archive.org/web/20200616084146/https://slatestarcodex.com/2020/04/01/book-review-the-precipice/">we are currently facing a critical period</a>
    during with such existential threats are especially pressing, making the task
    of addressing these issues right now very important. Natural disasters like meteor
    strikes, volcanoes, or even natural pandemics are unlikely to make us go extinct
    (though they can obviously cause significant suffering). Somewhat perversely,
    the greatest threats we face come from ourselves. Nuclear war, although still
    unlikely to totally annihilate us, could easily come very close and certainly
    cause unprecedented destruction; despite a decline in the attention paid to it
    since the Cold War,
    <a href="https://samharris.org/podcasts/210-logic-doomsday/">this threat is perhaps more pressing than ever before and deserves our
        attention</a>. Man-made pathogens could also prove much more dangerous than naturally
    occurring ones and could lead to our extinction. Climate change is set to
    lead to very costly problems down the road; again, this probably won’t drive
    us extinct, but it <em>might</em>, and it deserves attention in any case.
    One threat that many people may be unaware of, but nonetheless is making
    some
    <a href="https://en.wikipedia.org/wiki/Human_Compatible">very smart people quite concerned</a>, is the potential for superintelligent artificial intelligences to go
    awry, start acting against our best interests, and destroy or otherwise
    incapacitate us. This admittedly sounds like science fiction, but given that
    it is an unprecedented threat and that our future society will very likely
    rely heavily on intelligent machines, it seems that significant caution is
    merited.
</p>

<p>I should note that none of the above-listed threats are guaranteed to
    materialize. However, if we think probabilistically and consider how bad it
    would be if they did happen, we realize that they deserve way more attention
    than they’re currently getting.
</p>

<h3>Stagnation</h3>

<p>Even if we don’t go extinct, it is still possible that we might fail to
    continue progressing technologically a point where we can achieve the future
    I have imagined. There are lots of reasons why this could happen — for
    example, any of the extinction threats above could also just set humanity
    back to a point where further technological progress is impossible, our
    institutions could decay to a point where they are not efficient enough to
    produce new innovations but still somehow stable enough to persist, or we
    may have just already picked all the low-hanging scientific fruit. It
    already seems to be the case that <a href="https://conversationswithtyler.com/episodes/peter-thiel/">technological progress has been slowing down in the past few decades</a>, and
    <a href="https://www.ted.com/talks/robert_gordon_the_death_of_innovation_the_end_of_growth">future growth may be much more difficult than it has been</a> since the start of the industrial revolution. We should look carefully into
    the causes of possible stagnation and reform our institutions to address them.
    Perhaps the best place to start is by reforming the educational and academic
    institutions to actually teach effectively and to incentivize groundbreaking
    research instead of persisting in centuries-old hierarchical structures and processes
    that require endless hoop-jumping.
</p>

<h3 id="derailment">Derailment</h3>

<p>A worrisome trend I have seen over the past couple of decades, fomented
    especially by the internet, is the derailment of human psychology in favor
    of the endless consumption of goods whose impact on our well-being is not
    obviously positive. I see lots of people wondering whether services like
    social media are actually net positives — most of these worries focus on the
    impact of those services on individual mental health and productivity
    (certainly worth paying attention to!), but those effects are only some of
    the ways in which technology may affect our long-term potential to create a
    healthier and more robust society. We have already seen how the
    resource-extraction technologies of the past century have blighted the
    planet; shouldn’t we have learned our lesson to be more careful with
    deploying transformative technologies when our collective future is on the
    line?
</p>

<p>I don’t want to be misunderstood: I am strongly in favor of technological
    progress, but only insofar as it actually constitutes <em>progress</em> — that
    is, as far as it promotes our collective well-being and moves us closer to the
    goals I have outlined above. The internet and other modern innovations do make
    possible many services I find to be incredibly useful (shout out to my friend
    Wikipedia), but at the same time it is unclear to me how services that allow
    us to wile away our time reading hollow jokes and to constantly feel inferior
    to the air-brushed celebrities and “influencers” that have suddenly come to be
    neighbors with us in our (virtual) communities are a step in the right direction.
    The most successful online tech companies use clever and sophisticated “machine
    learning” algorithms to get a detailed idea of users’ interests and preferences
    so they can more effectively tug on our emotions and market us more goods of
    questionable worth. Surely we can find better uses for these innovations?
</p>

<blockquote class="wp-block-quote"><p>We wanted flying cars, instead we got 140 characters.</p>
    <cite>Peter Thiel</cite></blockquote>

<h3>Subjugation</h3>

<p>Even if we manage to dodge all of the obstacles mentioned so far, we may
    still not be completely in the clear. Selfish interests may still deter us
    from our goal. After all, the idealistic visions of many of the past
    projects meant to better the lot of mankind were turned sour in part because
    of the excessive concentration of power and subsequent abuse of that power.
</p>

<p>Wealth inequality has received a lot of attention in the U.S. in recent
    years, and, while the issue is more complicated than is commonly portrayed
    in mainstream treatments of the subject, it is still quite clear that
    something has changed about the modern economic system that leads to some
    individuals possessing outrageous monetary power. Although there may be some
    advantages to some individuals having such power — for example, people like
    Bill and Melinda Gates perform charitable work at a larger scale and more
    efficiently than any government group I am aware of — the current situation
    is still concerning and can only be expected to intensify as globalization
    continues and improved technology increasingly rewards holders of capital
    more than laborers. The former factor — globalization — does seem to be
    facing friction from things like Brexit and Trump-style isolationism, but
    the <a href="https://en.wikipedia.org/wiki/Belt_and_Road_Initiative">actions of nations like China</a>
    and the increasing interconnectedness of everything facilitated by the internet
    suggest that the march of global economic entanglement will continue. The latter
    factor — automation of labor — seems slated to be an even greater contributor
    to wealth inequality, and one that is not likely to slack off anytime soon. As
    I’ve already mentioned, humans will increasingly find themselves outmoded by
    machines in their occupations, and
    <a href="https://wol.iza.org/articles/who-owns-the-robots-rules-the-world/long">whoever owns the machines will find themselves rolling in the dough</a>. It is a mistake to think that anyone’s job is immune to automation:
    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3482150">even highly-educated workers could find themselves replaced</a>
    by the next generation of pseudo-intelligent machines. Absent
    <em>carefully</em>-designed public policy to fairly distribute the new
    machine-generated wealth, I’m worried that we may find ourselves facing a
    dystopian scene of subjugation by the capital-holding elite. On the other
    hand, if we can avoid that scenario, the potentially gains to the whole of
    humanity are immense.
</p>

<h2>Conclusion</h2>

<p>Humanity’s future lies along a path promising both great rewards and
    formidable obstacles. If we can successfully navigate the obstacles in our
    way, we can arrive at a future characterized by pleasant, meaningful, and
    healthy lives; guaranteed rights and opportunities; great wealth; great
    technical and cultural achievements; and, overall, widespread moral
    achievement, whatever that may mean for the humans of the time.
</p>

<p>—</p>

<p>If you enjoyed this essay and want to think more carefully about these
    issues and be involved in making a better future, here are some resources
    I’ve found helpful:
</p>

<ul><li><a href="https://80000hours.org/">80,000 hours</a> for well-thought-out advice
        about how to have an impactful career. Many of their focus areas involve
        issues touched upon here.
    </li>
    <li>Works of fiction like Iain Banks’ <a href="https://www.goodreads.com/series/49118-culture">Culture series</a> to help you get excited about what our collective future could look like.
    </li>
    <li>Podcasts to help you be better-informed about social and economic issues
        that contribute to or detract from our collective flourishing — here are
        some of my favorites: <a href="https://conversationswithtyler.com/">Conversations with Tyler</a>, <a href="https://www.econtalk.org/">EconTalk</a>, the
        <a href="https://80000hours.org/podcast/">80,000 hours podcast</a>.
    </li>
    <li>Technical books to help structure your thinking about our aggregate
        well-being — here’s one I’ve been reading recently (free as of July
        2020): <a href="https://link.springer.com/book/10.1007/978-3-319-50319-6">Economics as Applied Ethics</a>.
    </li></ul></div></div>
<div class="max-w-xs mx-auto py-4"><footer class="bg-red-400 rounded-lg shadow-md">
        <div class="flex flex-row justify-center"><a class="flex mx-4 my-2 text-2xl text-white" href="https://github.com/quevivasbien/"><i class="fab fa-github"></i></a>
                <a class="flex mx-4 my-2 text-2xl text-white" href="mailto:jensenm@uchicago.edu"><i class="fa fa-envelope"></i></a>
                <a class="flex mx-4 my-2 text-2xl text-white" href="https://www.linkedin.com/in/mckaydjensen/"><i class="fab fa-linkedin"></i></a></div></footer></div>
<div class="flex flex-col items-center justify-center pb-3"><div>goodness, truth, and <span>humankind</span></div></div>


			
			<script>
				{
					__sveltekit_1jtjssb = {
						base: new URL("../..", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null,null];

					Promise.all([
						import("../../_app/immutable/entry/start.e7abbd9d.js"),
						import("../../_app/immutable/entry/app.6de9baa2.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2, 13],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
